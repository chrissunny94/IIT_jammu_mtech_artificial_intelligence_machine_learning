{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, let's break down the code mathematically for each image processing technique:\n",
    "\n",
    "1. **Smoothing Linear Filters** (Gaussian Blur):\n",
    "   - Mathematically, Gaussian blur is achieved by convolving the image with a Gaussian kernel.\n",
    "   - The Gaussian kernel is a 2D distribution defined by the Gaussian function:\n",
    "     \\[ G(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2+y^2}{2\\sigma^2}} \\]\n",
    "   - Here, \\(\\sigma\\) is the standard deviation of the Gaussian distribution, which determines the amount of blur.\n",
    "   - The convolution operation involves sliding the Gaussian kernel over the image and computing the weighted sum of pixel values in the neighborhood of each pixel.\n",
    "   - This weighted sum replaces the central pixel value, resulting in a smoothed version of the image.\n",
    "\n",
    "2. **First- and Second-Order Derivatives** (Sobel Filters for Edge Detection):\n",
    "   - Sobel filters are used to compute the gradient of the image intensity.\n",
    "   - Mathematically, the Sobel operator performs convolution with two kernels: one for detecting vertical edges (Sobel X) and another for detecting horizontal edges (Sobel Y).\n",
    "   - These kernels approximate the derivative of the image intensity function in the horizontal and vertical directions, respectively.\n",
    "   - The magnitude of the gradient at each pixel is computed as the square root of the sum of squares of the gradients in both directions.\n",
    "   - This magnitude represents the strength of the edge at that pixel.\n",
    "   - Additionally, the direction of the gradient can be computed using the arctangent function.\n",
    "\n",
    "3. **Histogram Example** (Histogram Equalization):\n",
    "   - Histogram equalization is a technique used to enhance the contrast of an image.\n",
    "   - Mathematically, it involves redistributing the intensity values of the image such that the histogram becomes approximately uniform.\n",
    "   - This is achieved by computing the cumulative distribution function (CDF) of the histogram and mapping the original pixel values to new values based on this function.\n",
    "   - Pixels with lower intensity values are stretched to occupy a wider range of intensity levels, resulting in improved contrast.\n",
    "\n",
    "4. **Spatial Correlation and Convolution** (Linear Spatial Filtering):\n",
    "   - Linear spatial filtering involves convolving the image with a filter kernel.\n",
    "   - Mathematically, convolution is performed by sliding the filter kernel over the image and computing the element-wise product of the kernel and the corresponding image patch.\n",
    "   - The sum of these products gives the value of the central pixel in the filtered image.\n",
    "   - Linear filters are typically used for tasks such as blurring, sharpening, and edge detection.\n",
    "\n",
    "5. **Image Enhancement** (Contrast Stretching):\n",
    "   - Contrast stretching is a simple image enhancement technique used to improve the contrast of an image.\n",
    "   - Mathematically, it involves linearly scaling the intensity values of the image to span the full range of available pixel values (e.g., 0 to 255).\n",
    "   - This is done by finding the minimum and maximum intensity values in the image and scaling all pixel values proportionally.\n",
    "   - Pixels with intensities close to the minimum value are mapped to 0, while pixels with intensities close to the maximum value are mapped to 255.\n",
    "\n",
    "6. **Gaussian Filters** (Smoothing Using Gaussian Blur):\n",
    "   - Same as the first point, Gaussian blur is achieved by convolving the image with a Gaussian kernel.\n",
    "   - The Gaussian kernel smooths the image by averaging the pixel values in the neighborhood of each pixel, with more weight given to nearby pixels according to the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filter(frame):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Sobel filters\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    \n",
    "    display_image('Sobel X', sobel_x)\n",
    "    display_image('Sobel Y', sobel_y)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def histogram_rquilization(frame):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equ = cv2.equalizeHist(gray)\n",
    "    \n",
    "    display_image('Histogram Equalized', equ)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter2d(frame):\n",
    "    # Define kernel for linear filter\n",
    "    kernel = np.ones((5, 5), np.float32) / 25\n",
    "    \n",
    "    # Apply linear filter using convolution\n",
    "    filtered_frame = cv2.filter2D(frame, -1, kernel)\n",
    "    display_image('Filtered', filtered_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_stretching(frame):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply contrast stretching\n",
    "    min_val = np.min(gray)\n",
    "    max_val = np.max(gray)\n",
    "    stretched = 255 * (gray - min_val) / (max_val - min_val)\n",
    "    \n",
    "    display_image('Contrast Stretched', stretched.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blurr(frame):\n",
    "    # Apply Gaussian blur\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    \n",
    "    display_image('Blurred', blurred_frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(frame):\n",
    "    # Edge detection using Laplacian filter\n",
    "    laplacian = cv2.Laplacian(frame, cv2.CV_64F)\n",
    "    display_image('Laplacian', laplacian)\n",
    "    # Gradient computation using Sobel filters\n",
    "    sobel_x = cv2.Sobel(frame, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(frame, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    display_image('Sobel X', sobel_x)\n",
    "    display_image('Sobel Y', sobel_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "import cv2\n",
    "\n",
    "from cv2 import cvtColor , COLOR_BGR2RGB , TERM_CRITERIA_MAX_ITER , KMEANS_RANDOM_CENTERS ,TERM_CRITERIA_EPS ,kmeans\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "from numpy import unique , float32 , uint8\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "#from enum import unique\n",
    "#Read an RGB image as input.(DONE)\n",
    "\n",
    "def read_image(path_to_image):\n",
    "    image=cv2.imread(path_to_image)\n",
    "    return image\n",
    "\n",
    "def display_image(title,image):\n",
    "    #cv2.imshow(\"input_image\",image)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "size = (int(cap.get(cv.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*\"MP4V\")\n",
    "out = cv.VideoWriter('output.mp4', fourcc, 15, size)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # write the flipped frame\n",
    "    # out.write(frame)\n",
    "    sobel_filter(frame)\n",
    "    histogram_rquilization(frame)\n",
    "    filter2d(frame)\n",
    "    contrast_stretching(frame)\n",
    "    gaussian_blurr(frame)\n",
    "    laplacian(frame)\n",
    "    # cv.imshow('frame', frame)\n",
    "    # if cv.waitKey(1) == ord('q'):\n",
    "    #     break\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 11:40:31.718 Python[34447:4002997] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     10\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the concepts mentioned in the summary using Python and OpenCV, we can focus on edge detection using gradient masks and image derivatives. Here's how we can achieve this:\n",
    "\n",
    "Gradient Masks:\n",
    "\n",
    "We'll use Sobel filters to compute the gradient of the image intensity in both the horizontal and vertical directions.\n",
    "Sobel filters are commonly used for edge detection due to their simplicity and effectiveness.\n",
    "Edge Detection:\n",
    "\n",
    "We'll apply Laplacian masks to detect edges in the image.\n",
    "Laplacian masks highlight regions of rapid intensity change, which typically correspond to edges in the image.\n",
    "Second Order Derivatives:\n",
    "\n",
    "Laplacian filters are second-order derivative filters that emphasize areas of rapid intensity change.\n",
    "They are useful for sharpening images by accentuating edges.\n",
    "First Order Image Derivatives:\n",
    "\n",
    "Sobel filters, used for gradient computation, are first-order derivative filters.\n",
    "They detect changes in intensity along the horizontal and vertical axes of the image.\n",
    "These filters are effective for detecting edges and gradients in images.\n",
    "Let's write Python code snippets to demonstrate these concepts using OpenCV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "We load an image and convert it to grayscale.\n",
    "We compute gradients in the horizontal and vertical directions using Sobel filters (sobel_x and sobel_y).\n",
    "We apply the Laplacian filter to detect edges (laplacian).\n",
    "Finally, we display the original image along with the results of gradient computation and edge detection.\n",
    "This code demonstrates the use of gradient masks and image derivatives for edge detection and emphasizes areas of rapid intensity change in the image.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
